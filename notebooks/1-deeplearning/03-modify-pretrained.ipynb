{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image processing\n",
    "from keras.preprocessing import image as image_utils\n",
    "\n",
    "# pretrained nets\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_files_path = \"/keras2production/fruits/Training/\"\n",
    "valid_image_files_path = \"/keras2production/fruits/Test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_list = [\"Apricot\", \"Avocado\", \"Banana\", \"Clementine\", \"Cocos\", \"Kiwi\", \"Lemon\", \"Limes\", \n",
    "              \"Mandarine\", \"Orange\", \"Peach\", \"Pineapple\", \"Plum\", \"Pomegranate\", \"Raspberry\", \n",
    "              \"Strawberry\"]\n",
    "output_n = len(fruit_list)\n",
    "img_width = 32\n",
    "img_height = 32\n",
    "channels = 3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained nets\n",
    "\n",
    "https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify VGG16\n",
    "\n",
    "- transfer learning (freeze all but the penultimate layer and re-train the last Dense layer) and \n",
    "- fine tuning (un-freeze the lower convolutional layers and retrain more layers)\n",
    "\n",
    "Validation set: fit_generator has no option validation_split\n",
    "\n",
    "https://keras.io/applications/#usage-examples-for-image-classification-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important: exclude top layers\n",
    "# we can define our own input_shape, since VGG only provides the learned kernels\n",
    "base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                   input_shape=(img_width, img_height, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255\n",
    ")\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255\n",
    ")\n",
    "\n",
    "train_image_array_gen = train_data_gen.flow_from_directory(\n",
    "    train_image_files_path,\n",
    "    target_size = (img_width, img_height),\n",
    "    class_mode = 'categorical',\n",
    "    classes = fruit_list,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    seed = 42)\n",
    "\n",
    "valid_image_array_gen = valid_data_gen.flow_from_directory(\n",
    "    valid_image_files_path,\n",
    "    target_size = (img_width, img_height),\n",
    "    class_mode = 'categorical',\n",
    "    classes = fruit_list,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the data generator is set up correctly\n",
    "input_shape = train_image_array_gen.image_shape\n",
    "classes = train_image_array_gen.class_indices\n",
    "num_classes = len(classes)\n",
    "class_counts = np.unique(train_image_array_gen.classes, return_counts=True)[1]\n",
    "print(\"Shape:\" + str(input_shape))\n",
    "print(\"Number of classes:\" + str(num_classes))\n",
    "print(\"Classes:\" + str(classes))\n",
    "\n",
    "chart = plt.bar(classes.keys(), class_counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_image_array_gen.n\n",
    "valid_samples = valid_image_array_gen.n\n",
    "print(train_samples, valid_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    " \n",
    "# Add the base model\n",
    "model.add(base_model)\n",
    " \n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_n, activation='softmax'))\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = RMSprop(lr = 0.0001, decay = 1e-6),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_image_array_gen,\n",
    "    steps_per_epoch = int(train_samples / batch_size), \n",
    "    epochs = 3, \n",
    "    validation_data = valid_image_array_gen,\n",
    "    validation_steps = int(valid_samples / batch_size),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model_pre.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('model_pre_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreezing more layers, Early Stopping and Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "for layer in base_model.layers:\n",
    "    if layer.name.startswith('block5_conv'):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "top_weights_path = 'top_model.h5'\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(top_weights_path, monitor = 'val_acc', \n",
    "                    verbose = 1, save_best_only = True),\n",
    "    EarlyStopping(monitor = 'val_acc', patience = 5, verbose = 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = RMSprop(lr = 0.000001, decay = 1e-6),\n",
    "              metrics = ['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_image_array_gen,\n",
    "      steps_per_epoch = int(train_samples / batch_size),\n",
    "      epochs = 5,\n",
    "      validation_data = valid_image_array_gen,\n",
    "      validation_steps = int(valid_samples / batch_size),\n",
    "      callbacks = callbacks_list,\n",
    "      verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture\n",
    "with open('fruits_classifier_fine_tuned_vgg16.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('top_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_files_path = \"/keras2production/notebooks/1-deeplearning/test_images/\"\n",
    "test_images = !find $test_image_files_path -type f -name \"*.jpg\"\n",
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images[0]\n",
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_image_array_gen.class_indices\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_model(image, classes=classes):\n",
    "    img = cv2.imread(image)        \n",
    "    b,g,r = cv2.split(img)       # get b,g,r\n",
    "    img = cv2.merge([r,g,b])     # switch it to rgb\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    image = image_utils.load_img(image, target_size=(img_width, img_height))\n",
    "    image = image_utils.img_to_array(image)\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # scale pixels between 0 and 1, sample-wise\n",
    "    image /= 255.\n",
    "        \n",
    "    prediction = model.predict(image)\n",
    "    \n",
    "    pred = prediction.argmax()\n",
    "\n",
    "    for k, v in classes.items():\n",
    "        if (v == pred):\n",
    "            pred_label = k\n",
    "        \n",
    "    proba = prediction.max()\n",
    "    \n",
    "    print(\"Predicted class: \" + pred_label + \n",
    "          \" with probability \" + str(proba*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image_model(test_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
